{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f349b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Optional, Any\n",
    "import google.generativeai as genai\n",
    "\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.base import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a852a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Set your API key here or via .env\n",
    "genai.configure(api_key=\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f6e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Gemini LLM wrapper\n",
    "class GeminiLLM(LLM):\n",
    "    model: Any = None\n",
    "    model_name: str = \"models/gemini-1.5-flash\"\n",
    "    temperature: float = 0.7\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = genai.GenerativeModel(self.model_name)\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        response = self.model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"gemini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66faf1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Load all .pdf and .txt files from folder\n",
    "def load_documents(folder_path):\n",
    "    docs = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        path = os.path.join(folder_path, file)\n",
    "        if file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(path)\n",
    "        elif file.endswith(\".txt\"):\n",
    "            loader = TextLoader(path)\n",
    "        else:\n",
    "            continue\n",
    "        docs.extend(loader.load())\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db628bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Create persistent ChromaDB vector store\n",
    "def create_vectorstore(documents, save_path=\"chroma_store\"):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    # print(\"ðŸ§© Number of chunks:\", len(chunks))\n",
    "\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=save_path\n",
    "    )\n",
    "\n",
    "    vectorstore.persist()\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ee6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Answering questions using Gemini + Chroma\n",
    "def ask_question(vectorstore, question):\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    gemini = GeminiLLM()\n",
    "\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are a helpful assistant. Use the following context to answer the question.\n",
    "If you don't know the answer, just say you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=gemini,\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\"prompt\": prompt_template},\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "    result = qa({\"query\": question})\n",
    "    print(\"\\nðŸ“Œ Answer:\\n\", result['result'])\n",
    "\n",
    "    print(\"\\nðŸ“„ Sources used:\")\n",
    "    for doc in result['source_documents']:\n",
    "        print(\"-\", doc.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Main workflow\n",
    "if __name__ == \"__main__\":\n",
    "    chroma_path = \"chroma_store\"\n",
    "\n",
    "    if not os.path.exists(chroma_path):\n",
    "        os.makedirs(chroma_path)\n",
    "\n",
    "    if not os.path.exists(os.path.join(chroma_path, \"chroma.sqlite\")):\n",
    "        print(\"ðŸ“¥ Loading and embedding documents...\")\n",
    "        docs = load_documents(\"docs/\")\n",
    "        vs = create_vectorstore(docs, save_path=chroma_path)\n",
    "    else:\n",
    "        print(\"ðŸ“¦ Loading Chroma vector store...\")\n",
    "        embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "        vs = Chroma(persist_directory=chroma_path, embedding_function=embeddings)\n",
    "        vs.persist()\n",
    "\n",
    "    # ðŸ”„ Ask questions in a loop\n",
    "    while True:\n",
    "        query = input(\"\\nðŸ’¬ Ask a question (or 'exit'): \")\n",
    "        if query.lower() == \"exit\":\n",
    "            break\n",
    "        ask_question(vs, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ddbf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
