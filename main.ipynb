{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f71385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd5341",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"your_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c75ad543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Remove scripts and styles\n",
    "    for script in soup([\"script\", \"style\", \"img\", \"video\", \"iframe\"]):\n",
    "        script.decompose()\n",
    "\n",
    "    # Get clean text\n",
    "    text = soup.get_text(separator=\"\\n\")\n",
    "    cleaned_text = ' '.join(text.split())\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e73efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_gemini(text):\n",
    "    model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n",
    "    prompt = f\"\"\"\n",
    "Please generate a **detailed summary** of the following webpage content.\n",
    "Make sure it covers all key points, uses **bullet points**, includes **subheadings** where relevant,\n",
    "and avoids any reference to images, videos, or links.\n",
    "\n",
    "Text content:\n",
    "{text}\n",
    "\"\"\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c102d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219ee048",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = input(\"Enter the url for the website: \")\n",
    "text = extract_text_from_url(url)\n",
    "summary = summarize_with_gemini(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ea8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def pretty_display(summary):\n",
    "    sections = summary.split(\"\\n\\n\")\n",
    "\n",
    "    display(Markdown(\"## üìÑ **SUMMARY OF THE PAGE**\"))\n",
    "\n",
    "    for section in sections:\n",
    "        lines = section.strip().split(\"\\n\")\n",
    "        if not lines:\n",
    "            continue\n",
    "\n",
    "        heading = lines[0].strip().replace(\":\", \"\").upper()\n",
    "        display(Markdown(f\"### üü© **{heading}**\"))  # Bigger font for heading\n",
    "\n",
    "        for line in lines[1:]:\n",
    "            clean_line = line.strip().lstrip(\"*\").strip()\n",
    "            if clean_line:\n",
    "                display(Markdown(f\"- {clean_line}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8902f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty_display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf7bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcc43233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary_to_markdown(summary, filename=\"summary.md\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as md_file:\n",
    "        md_file.write(\"# Website Summary\\n\\n\")\n",
    "        md_file.write(summary)\n",
    "    print(\"‚úÖ Summary saved at:\", os.path.abspath(\"summary.md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fbc72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary saved at: c:\\Users\\HP\\OneDrive\\Desktop\\Project\\prompt_eng\\summarizer\\summary.md\n"
     ]
    }
   ],
   "source": [
    "save_summary_to_markdown(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee3732a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "def extract_clean_text_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Remove scripts/styles\n",
    "        for tag in soup([\"script\", \"style\"]):\n",
    "            tag.decompose()\n",
    "\n",
    "        # Get clean text\n",
    "        text = soup.get_text(separator=\"\\n\")\n",
    "        cleaned = \"\\n\".join([line.strip() for line in text.splitlines() if line.strip()])\n",
    "        return cleaned\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching webpage: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6efb26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_keyword(keyword, summary_file_path, source_url):\n",
    "    try:\n",
    "        with open(summary_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            summary = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è Summary file not found.\")\n",
    "        return\n",
    "\n",
    "    keyword_lower = keyword.lower()\n",
    "\n",
    "    if keyword_lower in summary.lower():\n",
    "        print(f\"\\n‚úÖ Keyword '{keyword}' found in summary.\\n\")\n",
    "        for line in summary.split(\"\\n\"):\n",
    "            if keyword_lower in line.lower():\n",
    "                print(\"‚Ä¢\", line.strip())\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Keyword '{keyword}' not found in summary. Now searching the web...\\n\")\n",
    "        webpage_text = extract_clean_text_from_url(source_url)\n",
    "\n",
    "        if not webpage_text:\n",
    "            print(\"‚ùå Failed to extract text from the web.\")\n",
    "            return\n",
    "\n",
    "        keyword_lines = [line for line in webpage_text.split(\"\\n\") if keyword_lower in line.lower()]\n",
    "\n",
    "        if keyword_lines:\n",
    "            print(f\"üîé Found keyword '{keyword}' on the webpage. Here's a mini summary:\\n\")\n",
    "            for line in keyword_lines[:5]:  # Show top 5 relevant lines\n",
    "                print(\"‚Ä¢\", line.strip())\n",
    "        else:\n",
    "            print(\"‚ùå No such keyword found on the webpage either.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9b3ce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary logged to 'history.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def log_summary(source_url, summary_file_path, summary_text=None, model_used=\"Gemini\"):\n",
    "    history_file = \"history.json\"\n",
    "\n",
    "    if os.path.exists(history_file):\n",
    "        try:\n",
    "            with open(history_file, \"r\") as f:\n",
    "                history = json.load(f)\n",
    "            if not isinstance(history, dict):\n",
    "                history = {}\n",
    "        except json.JSONDecodeError:\n",
    "            history = {}\n",
    "    else:\n",
    "        history = {}\n",
    "\n",
    "    summary_entry = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"source_url\": source_url,\n",
    "        \"summary_file\": os.path.basename(summary_file_path),\n",
    "        \"used_model\": model_used\n",
    "    }\n",
    "\n",
    "    if summary_text:\n",
    "        summary_entry[\"summary_preview\"] = summary_text[:200] + \"...\"\n",
    "\n",
    "    history.setdefault(\"summaries\", []).append(summary_entry)\n",
    "\n",
    "    with open(history_file, \"w\") as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "\n",
    "    print(f\"‚úÖ Summary logged to '{history_file}'\")\n",
    "\n",
    "\n",
    "log_summary(url, \"summary.md\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcd9491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_keyword = input(\"üîç Enter the keyword to search: \")\n",
    "summary_file_path = \"summary.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "232c8be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Keyword 'artificial' not found in summary. Now searching the web...\n",
      "\n",
      "üîé Found keyword 'artificial' on the webpage. Here's a mini summary:\n",
      "\n",
      "‚Ä¢ generative artificial intelligence\n",
      "‚Ä¢ artificial intelligence\n",
      "‚Ä¢ and artificial intelligence assistant based on large language models.\n",
      "‚Ä¢ Artificial intelligence content detection\n",
      "‚Ä¢ Reflection (artificial intelligence)\n"
     ]
    }
   ],
   "source": [
    "search_keyword(user_keyword, summary_file_path, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76188d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef16803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
